{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "if __name__ == '__main__' :\n",
    "\n",
    "    video = cv2.VideoCapture(\"C:/Users/umar.amanat/Desktop/Mot16-Venice-2.mp4\");\n",
    "    \n",
    "    # Find OpenCV version\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "    \n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "        print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "    else :\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "    \n",
    "    video.release(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating WIdth and Height of frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vcap = cv2.VideoCapture(\"C:/Users/umar.amanat/Desktop/Mot16-Venice-2.mp4\");\n",
    "\n",
    "if vcap.isOpened(): \n",
    "    height = vcap.get(cv2.CAP_PROP_FRAME_HEIGHT)   # float\n",
    "    width = vcap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    print(\"video height {} and width {}\".format(height, width))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving video frame after skipping particular number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "\n",
    "vid_fold_path = \"C:/Users/umar.amanat/Desktop\" #Video folder path\n",
    "video_path = \"MOT16-11.mp4\"\n",
    "\n",
    "vidcap = cv2.VideoCapture(os.path.join(vid_fold_path, video_path))\n",
    "total_frames = vidcap.get(7)\n",
    "fps = vidcap.get(cv2.cv2.CAP_PROP_FPS)   #fps of video\n",
    "success,image = vidcap.read() #read video\n",
    "skip_frame = 5  # number of frame to skip\n",
    "orig_height = vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT)   # original height of video\n",
    "orig_width = vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)     #original width of videos\n",
    "print(\"frame per second: \", fps)\n",
    "print(\"video height {} and width {}\".format(orig_height, orig_width))\n",
    "success = True    #flag for iterating through video's frame\n",
    "frame_count = 0         #count for storing video file\n",
    "scaled_height = int(orig_height/32) * 32  #scaled height for yolov2 algo\n",
    "scaled_width = int(orig_width/32) * 32    #scaled width for yolov2 algo\n",
    "print(\"scaled video height {} and scaled width {}\".format(scaled_height, scaled_width))\n",
    "\n",
    "image_count = 0 #counter for counting number of images per folder\n",
    "folder_count = 0 #counter for counting number of folder\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/DataSet\"\n",
    "\n",
    "\n",
    "saving_path = os.path.join(saving_path, \"folder_\")\n",
    "os.makedirs(saving_path+str(folder_count))\n",
    "\n",
    "diff_height = 0\n",
    "diff_widht = 0\n",
    "#Iterate till last frame of video\n",
    "while success:\n",
    "    if (frame_count%skip_frame == 0):\n",
    "        if(image_count<10):\n",
    "            diff_height = int(orig_height/2)-int(scaled_height/2)\n",
    "            diff_width = int(orig_width/2)-int(scaled_width/2)\n",
    "            image = image[diff_height : int(orig_height-diff_height), diff_width : int(orig_width-diff_width)]\n",
    "            cv2.imwrite(os.path.join(saving_path+str(folder_count), video_path+\"_\"+str(image_count))+\".png\" , image) \n",
    "            image_count += 1\n",
    "        else:\n",
    "            folder_count += 1;\n",
    "            saving_path = saving_path #os.path.join(saving_path, \"folder_\"+str(folder_count))\n",
    "            os.makedirs(saving_path+str(folder_count))\n",
    "            image_count = 0\n",
    "            \n",
    "    success,image = vidcap.read()    \n",
    "    frame_count += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brightening, Rotating Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    r_img = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)  \n",
    "    return r_img\n",
    "    #rotate func end here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightened_image(image, intensity):\n",
    "    \"\"\"\n",
    "    Argument info\n",
    "    image: input image\n",
    "    intesnity: Intensity for brightness\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #convert it to hsv\n",
    "    for x in range(0, len(hsv)):\n",
    "        for y in range(0, len(hsv[0])):\n",
    "            if(hsv[x, y][2] < 255 - intensity):\n",
    "                hsv[x, y][2] += intensity\n",
    "    \n",
    "    b_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR) \n",
    "    return b_img\n",
    "    #brightened image end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_blue(image, intensity):\n",
    "    \"\"\"\n",
    "    Argument info\n",
    "    image: input image\n",
    "    intesnity: Intensity for blue color\n",
    "    \"\"\"\n",
    "    for x in range(0, len(image)):\n",
    "        for y in range(0, len(image[0])):\n",
    "            if(image[x, y][0] < 255 - intensity):\n",
    "                image[x, y][0] += intensity\n",
    "    return image\n",
    "    #increase blue image end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_green(image, intensity):\n",
    "    \"\"\"\n",
    "    Argument info\n",
    "    image: input image\n",
    "    intesnity: Intensity for green color\n",
    "    \"\"\"\n",
    "    for x in range(0, len(image)):\n",
    "        for y in range(0, len(image[0])):\n",
    "            if(image[x, y][1] < 255 - intensity):\n",
    "                image[x, y][1] += intensity\n",
    "    return image\n",
    "    #increase green image end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_red(image, intensity):\n",
    "    \"\"\"\n",
    "    Argument info\n",
    "    image: input image\n",
    "    intesnity: Intensity for green color\n",
    "    \"\"\"\n",
    "    for x in range(0, len(image)):\n",
    "        for y in range(0, len(image[0])):\n",
    "            if(image[x, y][2] < 255 - intensity):\n",
    "                image[x, y][2] += intensity\n",
    "    return image\n",
    "    #increase red image end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kernel(image, kernel):\n",
    "    \"\"\"\n",
    "    Image: input image\n",
    "    Kernel : Specify 2D kernel to apply on image \n",
    "    \"\"\"\n",
    "    image = cv2.filter2D(image, -1, kernel)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_contrast(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=3., tileGridSize=(8,8))\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)  # convert from BGR to LAB color space\n",
    "    l, a, b = cv2.split(lab)  # split on 3 different channels\n",
    "    l2 = clahe.apply(l)  # apply CLAHE to the L-channel\n",
    "    lab = cv2.merge((l2,a,b))  # merge channels\n",
    "    img2 = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)  # convert from LAB to BGR\n",
    "    return img2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_noise(image):\n",
    "    row,col,ch = image.shape\n",
    "    s_vs_p = 0.5\n",
    "    amount = 0.004\n",
    "    out = np.copy(image)\n",
    "    # Salt mode\n",
    "    num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "          for i in image.shape]\n",
    "    out[coords] = 1\n",
    "\n",
    "    # Pepper mode\n",
    "    num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "          for i in image.shape]\n",
    "    out[coords] = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #Video folder path\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/TunedImages\"\n",
    "img_cnt = 0 #image_count\n",
    "angle = -0.5    #angle for rotation\n",
    "br_int = 35     #brightness intensity\n",
    "b_int = 35      #blue color intensity\n",
    "g_int = 35      #green intensity\n",
    "r_int = 35      #red intensity\n",
    "\n",
    "os.makedirs(saving_path)\n",
    "for image_path in glob.iglob(os.path.join(img_fold_path, \"*.png\")):\n",
    "    image = cv2.imread(image_path) #reading image\n",
    "    i_n = image_path.split(\"\\\\\")[-1].split(\".\")[0]    #extract image name from image path\n",
    "    t1 = time.time()\n",
    "    ######################## make image bright start ######################################\n",
    "    br_img = brightened_image(image.copy(), br_int)\n",
    "    print(\"Brightened image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, i_n+\"_bright_\"+str(img_cnt))+\".png\", br_img) \n",
    "    ######################## end######################################\n",
    "\n",
    "    t1 = time.time()    \n",
    "    ######################## Rotate image start ######################################\n",
    "    rot_img = rotate_image(image.copy(), angle)    #rotated image\n",
    "    print(\"Rotate image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, i_n+\"_rotate_\"+str(img_cnt))+\".png\", rot_img) \n",
    "    ######################## end ######################################\n",
    "    \n",
    "    t1 = time.time()    \n",
    "    ######################## increase blue intensity start ######################################\n",
    "    blue_img = increase_blue(image.copy(), b_int)    \n",
    "    print(\"increase blue color {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, i_n+\"_blue_\"+str(img_cnt))+\".png\", blue_img) \n",
    "    ######################## end ######################################\n",
    "    \n",
    "    t1 = time.time()    \n",
    "    ######################## increase green intensity start ######################################\n",
    "    green_img = increase_green(image.copy(), g_int)    \n",
    "    print(\"increase green color {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, i_n+\"_green_\"+str(img_cnt))+\".png\", green_img) \n",
    "    ######################## end ######################################\n",
    "    \n",
    "    \n",
    "    t1 = time.time()    \n",
    "    ######################## increase green intensity start ######################################\n",
    "    red_img = increase_red(image.copy(), g_int)    \n",
    "    print(\"increase red color {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, i_n+\"_red_\"+str(img_cnt))+\".png\", red_img) \n",
    "    ######################## end ######################################\n",
    "\n",
    "    t1 = time.time()    \n",
    "    ######################## image sharpening ######################################\n",
    "    sharp_kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "    sh_img = apply_kernel(image.copy(), sharp_kernel)    #sharp image\n",
    "    print(\"Sharpened image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, i_n+\"_sharp_\"+str(img_cnt))+\".png\", sh_img) \n",
    "    ######################## end ######################################\n",
    "    \n",
    "    t1 = time.time()\n",
    "    ######################## increase contrast ######################################\n",
    "    inc_cont = increase_contrast(image.copy())\n",
    "    print(\"Increase contrast {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, i_n+\"_contrast_\"+str(img_cnt))+\".png\", inc_cont) \n",
    "    ######################## end ######################################\n",
    "    \n",
    "    \n",
    "    t1 = time.time()\n",
    "    ######################## Adding noise in images ######################################\n",
    "    noise_img = adding_noise(image.copy())\n",
    "    print(\"Adding noise in image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, i_n+\"_noise_\"+str(img_cnt))+\".png\", noise_img) \n",
    "    ######################## end ######################################\n",
    "   \n",
    "    img_cnt+=1\n",
    "    \n",
    "print(\"Augmentation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following script are only for flipped of annotated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### flipping annotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #images folder path\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/Flipped_Images\"  #saving path for images\n",
    "ann_svg_path = \"C:/Users/umar.amanat/Desktop/Flipped_Images\"   #path for saving annotation\n",
    "\n",
    "\n",
    "img_ann_path = \"C:/Users/umar.amanat/Desktop/Images/via_region_data.csv\"  #path for annotated\n",
    "ann_csv = pd.read_csv(img_ann_path)\n",
    "labels = ann_csv[\"#filename\"] \n",
    "tuples = list(zip(labels, ann_csv.index.values))\n",
    "hier_index = pd.MultiIndex.from_tuples(tuples)\n",
    "ann_csv.set_index(hier_index, inplace=True)\n",
    "ann_csv.drop(columns=[\"#filename\", \"file_attributes\", \"region_attributes\"], inplace=True)\n",
    "\n",
    "img_cnt = 0\n",
    "os.makedirs(saving_path)\n",
    "for image_path, image_name in zip(glob.iglob(os.path.join(img_fold_path, \"*.png\")), ann_csv.index.levels[0]):\n",
    "    image = cv2.imread(image_path) #reading image\n",
    "    \n",
    "     ####################### Flipping image ######################################\n",
    "    hor_flip = cv2.flip( image.copy(), 1 )\n",
    "#     print(\"Flipping image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, image_path.split(\"\\\\\")[-1].split(\".\")[0]+\"_flip_\"+str(img_cnt))+\".png\", hor_flip) \n",
    "    ######################## end ######################################\n",
    "    \n",
    "    #################FLipping of annotation start here4 ################\n",
    "    for box in ann_csv.loc[image_name].index:\n",
    "        dim = ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"]\n",
    "        json_string = json.loads(dim)\n",
    "        json_string['x'] = image.shape[1] - json_string['x'] - json_string['width']\n",
    "        ann_csv.replace(to_replace=dim, value=str(json_string), inplace=True)\n",
    "        ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"] = str(json_string)\n",
    "    \n",
    "    #######################end #####################\n",
    "    img_cnt+=1\n",
    "\n",
    "    #for end here\n",
    "#major for end here    \n",
    "\n",
    "#write annotation to new csv file\n",
    "ann_csv.to_csv(os.path.join(ann_svg_path, \"flip_annotation.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shift annotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os \n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #images folder path\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/shifted_images\"  #saving path for images\n",
    "ann_svg_path = \"C:/Users/umar.amanat/Desktop/shifted_images\"   #path for saving annotation\n",
    "\n",
    "\n",
    "img_ann_path = \"C:/Users/umar.amanat/Desktop/Images/via_region_data.csv\"  #path for annotated\n",
    "ann_csv = pd.read_csv(img_ann_path)\n",
    "labels = ann_csv[\"#filename\"] \n",
    "tuples = list(zip(labels, ann_csv.index.values))\n",
    "hier_index = pd.MultiIndex.from_tuples(tuples)\n",
    "ann_csv.set_index(hier_index, inplace=True)\n",
    "ann_csv.drop(columns=[\"#filename\", \"file_attributes\", \"region_attributes\"], inplace=True)\n",
    "\n",
    "x_shift = 10    #shifting along x-axis\n",
    "y_shift = 10    #shifting along y-axis\n",
    "\n",
    "img_cnt = 0\n",
    "os.makedirs(saving_path)\n",
    "for image_path, image_name in zip(glob.iglob(os.path.join(img_fold_path, \"*.png\")), ann_csv.index.levels[0]):\n",
    "    image = cv2.imread(image_path) #reading image\n",
    "     ####################### Flipping image ######################################\n",
    "    num_rows, num_cols = image.copy().shape[:2]\n",
    "    translation_matrix = np.float32([ [1,0,x_shift], [0,1,y_shift] ])\n",
    "    shf_img = cv2.warpAffine(image.copy(), translation_matrix, (num_cols, num_rows))\n",
    "#     shf_img = cv2.copyMakeBorder(shf_img,y_shift*10,0,x_shift*10,10,cv2.BORDER_REFLECT_101)\n",
    "    cv2.imwrite(os.path.join(saving_path,image_path.split(\"\\\\\")[-1].split(\".\")[0]+ \"_shift_\"+str(img_cnt))+\".png\", shf_img) \n",
    "    ######################## end ######################################\n",
    "    \n",
    "    #################FLipping of annotation start here ################\n",
    "    for box in ann_csv.loc[image_name].index:\n",
    "        dim = ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"]\n",
    "        json_string = json.loads(dim)\n",
    "        json_string['x'] = json_string['x'] + x_shift \n",
    "        json_string['y'] = json_string['y'] + y_shift\n",
    "        ann_csv.replace(to_replace=dim, value=str(json_string), inplace=True)\n",
    "        ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"] = str(json_string)\n",
    "    \n",
    "    #######################end #####################\n",
    "    #inner for end here\n",
    "    img_cnt+=1\n",
    "#major for end here    \n",
    "\n",
    "#write annotation to new csv file\n",
    "ann_csv.to_csv(os.path.join(ann_svg_path, \"shift_annotation.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts for overlay transparent image on other background image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def transparentOverlay(src , overlay , pos=(0,0),scale = 1):\n",
    "    \"\"\"\n",
    "    :param src: Input Color Background Image\n",
    "    :param overlay: transparent Image (BGRA)\n",
    "    :param pos:  position where the image to be blit.\n",
    "    :param scale : scale factor of transparent image.\n",
    "    :return: Resultant Image\n",
    "    \"\"\"\n",
    "    overlay = cv2.resize(overlay,(0,0),fx=scale,fy=scale)\n",
    "    h,w,_ = overlay.shape  # Size of foreground\n",
    "    rows,cols,_ = src.shape  # Size of background Image\n",
    "    y,x = pos[0],pos[1]    # Position of foreground/overlay image\n",
    "    y = random.randint(y, y+20)\n",
    "    x = random.randint(x, x+20)\n",
    "    #loop over all pixels and apply the blending equation\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if x+i >= rows or y+j >= cols:\n",
    "                continue\n",
    "            alpha = float(overlay[i][j][3]/255.0) # read the alpha channel \n",
    "            src[x+i][y+j] = alpha*overlay[i][j][:3]+(1-alpha)*src[x+i][y+j]\n",
    "    return src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image 0\n",
      "Processed image 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random \n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #images folder path\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/OverlayImages\"  #saving path for images\n",
    "bag_image_path = \"C:/Users/umar.amanat/Desktop/shopping_bag_images\"\n",
    "\n",
    "img_ann_path = \"C:/Users/umar.amanat/Desktop/Images/via_region_data.csv\"  #path for annotated\n",
    "ann_csv = pd.read_csv(img_ann_path)\n",
    "labels = ann_csv[\"#filename\"] \n",
    "tuples = list(zip(labels, ann_csv.index.values))\n",
    "hier_index = pd.MultiIndex.from_tuples(tuples)\n",
    "ann_csv.set_index(hier_index, inplace=True)\n",
    "ann_csv.drop(columns=[\"#filename\", \"file_attributes\", \"region_attributes\"], inplace=True)\n",
    "\n",
    "img_cnt=0\n",
    "bag_img = cv2.imread(os.path.join(bag_image_path, \"world_cup.png\"), cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# if(bag_img.shape[0] > 400 & bag_img.shape[1] > 400):\n",
    "#     bag_img = cv2.resize(bag_img, (400, 400))\n",
    "\n",
    "os.makedirs(saving_path)\n",
    "for image_path, image_name in zip(glob.iglob(os.path.join(img_fold_path, \"*.png\")), ann_csv.index.levels[0]):\n",
    "    per_img = cv2.imread(image_path)\n",
    "    for box in ann_csv.loc[image_name].index:\n",
    "        dim = ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"]\n",
    "        json_string = json.loads(dim)\n",
    "        \n",
    "        #generate random size of bag \n",
    "        bag_img = cv2.resize(bag_img, (int(json_string['width']*random.randint(35, 40)/100), \n",
    "                                       int(json_string['height']*random.randint(35, 40)/100))\n",
    "                            , cv2.INTER_CUBIC)\n",
    "#         bag_x = random.randint(json_string['x'], json_string['x'] + bag_img.shape[1])\n",
    "        bag_y = json_string['y'] + json_string['height'] - int(bag_img.shape[0]*1.5)\n",
    "#         bag_y = random.randint(bag_y - 30, bag_y)\n",
    "\n",
    "\n",
    "#         per_img[bag_y:bag_y+bag_img.shape[0], bag_x:bag_x+bag_img.shape[1]] = bag_img\n",
    "        per_img = transparentOverlay(per_img, bag_img, pos=(json_string['x'], bag_y))\n",
    "        \n",
    "    #######################end #####################\n",
    "    #inner for end here\n",
    "    cv2.imwrite(os.path.join(saving_path,image_path.split(\"\\\\\")[-1].split(\".\")[0]+ \"_pwb_\"+str(img_cnt))+\".png\", per_img) \n",
    "    print(\"Processed image {}\".format(img_cnt))\n",
    "    img_cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script for handling transparency issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #images folder path\n",
    "bag_image_path = \"C:/Users/umar.amanat/Desktop/shopping_bag_images\"\n",
    "\n",
    "\n",
    "# We load the images\n",
    "l_img= cv2.imread(os.path.join(img_fold_path, \"7.png\"))\n",
    "s_img = cv2.imread(os.path.join(bag_image_path, \"world_cup.png\"), cv2.IMREAD_UNCHANGED) # Load with transparency\n",
    "\n",
    "s_img = cv2.resize(s_img, (500, 500))\n",
    "def transparentOverlay(src , overlay , pos=(0,0),scale = 1):\n",
    "    \"\"\"\n",
    "    :param src: Input Color Background Image\n",
    "    :param overlay: transparent Image (BGRA)\n",
    "    :param pos:  position where the image to be blit.\n",
    "    :param scale : scale factor of transparent image.\n",
    "    :return: Resultant Image\n",
    "    \"\"\"\n",
    "    overlay = cv2.resize(overlay,(0,0),fx=scale,fy=scale)\n",
    "    h,w,_ = overlay.shape  # Size of foreground\n",
    "    rows,cols,_ = src.shape  # Size of background Image\n",
    "    y,x = pos[0],pos[1]    # Position of foreground/overlay image\n",
    "    \n",
    "    #loop over all pixels and apply the blending equation\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if x+i >= rows or y+j >= cols:\n",
    "                continue\n",
    "            alpha = float(overlay[i][j][3]/255.0) # read the alpha channel \n",
    "            src[x+i][y+j] = alpha*overlay[i][j][:3]+(1-alpha)*src[x+i][y+j]\n",
    "    return src\n",
    "\n",
    "\n",
    "result = transparentOverlay(l_img, s_img)\n",
    "cv2.imshow('img', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "# cv2.imwrite(\"merged_transparent.png\", result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215, 234, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_img = cv2.imread(os.path.join(bag_image_path, \"world.png\"), cv2.IMREAD_UNCHANGED) # Load with transparency\n",
    "s_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images/img_1.jpg\" #Video folder path\n",
    "image = cv2.imread(img_fold_path)\n",
    "cv2.imshow('1', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " t1 = time.time()    \n",
    "    ######################## Unsharp Masking ######################################\n",
    "    sharp_kernel = -1./256 * np.array([[1, 4, 6, 4, 1], \n",
    "                                       [4, 16, 24, 16, 4], \n",
    "                                       [6, 24, -476, 25, 6],\n",
    "                                       [4, 16, 24, 16, 4],\n",
    "                                       [1, 4, 6, 4, 1]\n",
    "                                      ])\n",
    "    un_sh_mask = apply_kernel(image.copy(), sharp_kernel)    #sharp image\n",
    "    print(\"Unsharp masking image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "    cv2.imwrite(os.path.join(saving_path, \"un_sh_mk_\"+str(img_cnt))+\".png\", un_sh_mask) \n",
    "    ######################## end ######################################\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
