{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These scripts run perfectly on windows, on linux platform there will be issue due to path handling in linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "if __name__ == '__main__' :\n",
    "\n",
    "    video = cv2.VideoCapture(\"C:/Users/umar.amanat/Desktop/Mot16-Venice-2.mp4\");\n",
    "    \n",
    "    # Find OpenCV version\n",
    "    (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "    \n",
    "    if int(major_ver)  < 3 :\n",
    "        fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "        print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "    else :\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "    \n",
    "    video.release(); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating WIdth and Height of frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "vcap = cv2.VideoCapture(\"C:/Users/umar.amanat/Desktop/Mot16-Venice-2.mp4\");\n",
    "\n",
    "if vcap.isOpened(): \n",
    "    height = vcap.get(cv2.CAP_PROP_FRAME_HEIGHT)   # float\n",
    "    width = vcap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "    print(\"video height {} and width {}\".format(height, width))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving video frame after skipping particular number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "\n",
    "vid_fold_path = \"C:/Users/umar.amanat/Desktop\" #Video folder path\n",
    "video_path = \"MOT16-11.mp4\"\n",
    "\n",
    "vidcap = cv2.VideoCapture(os.path.join(vid_fold_path, video_path))\n",
    "total_frames = vidcap.get(7)\n",
    "fps = vidcap.get(cv2.cv2.CAP_PROP_FPS)   #fps of video\n",
    "success,image = vidcap.read() #read video\n",
    "skip_frame = 5  # number of frame to skip\n",
    "orig_height = vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT)   # original height of video\n",
    "orig_width = vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)     #original width of videos\n",
    "print(\"frame per second: \", fps)\n",
    "print(\"video height {} and width {}\".format(orig_height, orig_width))\n",
    "success = True    #flag for iterating through video's frame\n",
    "frame_count = 0         #count for storing video file\n",
    "scaled_height = int(orig_height/32) * 32  #scaled height for yolov2 algo\n",
    "scaled_width = int(orig_width/32) * 32    #scaled width for yolov2 algo\n",
    "print(\"scaled video height {} and scaled width {}\".format(scaled_height, scaled_width))\n",
    "\n",
    "image_count = 0 #counter for counting number of images per folder\n",
    "folder_count = 0 #counter for counting number of folder\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/DataSet\"\n",
    "\n",
    "\n",
    "saving_path = os.path.join(saving_path, \"folder_\")\n",
    "os.makedirs(saving_path+str(folder_count))\n",
    "\n",
    "diff_height = 0\n",
    "diff_widht = 0\n",
    "#Iterate till last frame of video\n",
    "while success:\n",
    "    if (frame_count%skip_frame == 0):\n",
    "        if(image_count<10):\n",
    "            diff_height = int(orig_height/2)-int(scaled_height/2)\n",
    "            diff_width = int(orig_width/2)-int(scaled_width/2)\n",
    "            image = image[diff_height : int(orig_height-diff_height), diff_width : int(orig_width-diff_width)]\n",
    "            cv2.imwrite(os.path.join(saving_path+str(folder_count), video_path+\"_\"+str(image_count))+\".png\" , image) \n",
    "            image_count += 1\n",
    "        else:\n",
    "            folder_count += 1;\n",
    "            saving_path = saving_path #os.path.join(saving_path, \"folder_\"+str(folder_count))\n",
    "            os.makedirs(saving_path+str(folder_count))\n",
    "            image_count = 0\n",
    "            \n",
    "    success,image = vidcap.read()    \n",
    "    frame_count += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color tuning script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "    image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "    r_img = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)  \n",
    "    return r_img\n",
    "    #rotate func end here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightened_image(image, intensity):\n",
    "    \"\"\"\n",
    "    Argument info\n",
    "    image: input image\n",
    "    intesnity: Intensity for brightness\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #convert it to hsv\n",
    "    for x in range(0, len(hsv)):\n",
    "        for y in range(0, len(hsv[0])):\n",
    "            if(hsv[x, y][2] < 255 - intensity):\n",
    "                hsv[x, y][2] += intensity\n",
    "    \n",
    "    b_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR) \n",
    "    return b_img\n",
    "    #brightened image end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_blue(image, intensity):\n",
    "    \"\"\"\n",
    "    Argument info\n",
    "    image: input image\n",
    "    intesnity: Intensity for blue color\n",
    "    \"\"\"\n",
    "    for x in range(0, len(image)):\n",
    "        for y in range(0, len(image[0])):\n",
    "            if(image[x, y][0] < 255 - intensity):\n",
    "                image[x, y][0] += intensity\n",
    "    return image\n",
    "    #increase blue image end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_green(image, intensity):\n",
    "    \"\"\"\n",
    "    Argument info\n",
    "    image: input image\n",
    "    intesnity: Intensity for green color\n",
    "    \"\"\"\n",
    "    for x in range(0, len(image)):\n",
    "        for y in range(0, len(image[0])):\n",
    "            if(image[x, y][1] < 255 - intensity):\n",
    "                image[x, y][1] += intensity\n",
    "    return image\n",
    "    #increase green image end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_red(image, intensity):\n",
    "    \"\"\"\n",
    "    Argument info\n",
    "    image: input image\n",
    "    intesnity: Intensity for green color\n",
    "    \"\"\"\n",
    "    for x in range(0, len(image)):\n",
    "        for y in range(0, len(image[0])):\n",
    "            if(image[x, y][2] < 255 - intensity):\n",
    "                image[x, y][2] += intensity\n",
    "    return image\n",
    "    #increase red image end here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kernel(image, kernel):\n",
    "    \"\"\"\n",
    "    Image: input image\n",
    "    Kernel : Specify 2D kernel to apply on image \n",
    "    \"\"\"\n",
    "    image = cv2.filter2D(image, -1, kernel)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_contrast(image):\n",
    "    clahe = cv2.createCLAHE(clipLimit=3., tileGridSize=(8,8))\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)  # convert from BGR to LAB color space\n",
    "    l, a, b = cv2.split(lab)  # split on 3 different channels\n",
    "    l2 = clahe.apply(l)  # apply CLAHE to the L-channel\n",
    "    lab = cv2.merge((l2,a,b))  # merge channels\n",
    "    img2 = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)  # convert from LAB to BGR\n",
    "    return img2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_noise(image):\n",
    "    row,col,ch = image.shape\n",
    "    s_vs_p = 0.5\n",
    "    amount = 0.004\n",
    "    out = np.copy(image)\n",
    "    # Salt mode\n",
    "    num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "          for i in image.shape]\n",
    "    out[coords] = 1\n",
    "\n",
    "    # Pepper mode\n",
    "    num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "          for i in image.shape]\n",
    "    out[coords] = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #Video folder path\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/TunedImages\"\n",
    "img_cnt = 0 #image_count\n",
    "angle = -0.5    #angle for rotation\n",
    "br_int = 35     #brightness intensity\n",
    "b_int = 35      #blue color intensity\n",
    "g_int = 35      #green intensity\n",
    "r_int = 35      #red intensity\n",
    "\n",
    "os.makedirs(saving_path)\n",
    "for sub_fold in glob.iglob(img_fold_path+\"/*\"):\n",
    "    img_ann_path = glob.iglob(sub_fold+\"/*.csv\")  #path for annotated csv file\n",
    "    ann_csv = pd.read_csv(list(img_ann_path)[-1])\n",
    "    labels = ann_csv[\"#filename\"] \n",
    "    tuples = list(zip(labels, ann_csv.index.values))\n",
    "    hier_index = pd.MultiIndex.from_tuples(tuples)\n",
    "    ann_csv.set_index(hier_index, inplace=True)\n",
    "    ann_csv.drop(columns=[\"#filename\",\"file_size\", \"region_count\", \"region_id\", \"file_attributes\"], inplace=True)\n",
    "    img_cnt=0\n",
    "    os.makedirs(os.path.join(saving_path, sub_fold.split('\\\\')[-1]))\n",
    "    img_cnt = 0\n",
    "    for image_path, image_name in zip(glob.iglob(os.path.join(sub_fold, \"*.png\")), ann_csv.index.levels[0]):\n",
    "        \n",
    "        image = cv2.imread(image_path) #reading image\n",
    "        image = cv2.imread(image_path) #reading image\n",
    "#         t1 = time.time()\n",
    "        ######################## make image bright start ######################################\n",
    "        br_img = brightened_image(image.copy(), br_int)\n",
    "#         print(\"Brightened image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_brght\"+\".png\", br_img) \n",
    "        ######################## end######################################\n",
    "\n",
    "#         t1 = time.time()    \n",
    "        ######################## Rotate image start ######################################\n",
    "        rot_img = rotate_image(image.copy(), angle)    #rotated image\n",
    "#         print(\"Rotate image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_rot\"+\".png\", rot_img)       \n",
    "        ######################## end ######################################\n",
    "\n",
    "#         t1 = time.time()    \n",
    "        ######################## increase blue intensity start ######################################\n",
    "        blue_img = increase_blue(image.copy(), b_int)    \n",
    "#         print(\"increase blue color {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_blue\"+\".png\", blue_img)    \n",
    "#         ######################## end ######################################\n",
    "\n",
    "#         t1 = time.time()    \n",
    "        ######################## increase green intensity start ######################################\n",
    "        green_img = increase_green(image.copy(), g_int)    \n",
    "#         print(\"increase green color {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_green\"+\".png\", green_img)   \n",
    "#         ######################## end ######################################\n",
    "\n",
    "\n",
    "#         t1 = time.time()    \n",
    "#         ######################## increase green intensity start ######################################\n",
    "        red_img = increase_red(image.copy(), g_int)    \n",
    "#         print(\"increase red color {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_red\"+\".png\", red_img)\n",
    "#         ######################## end ######################################\n",
    "\n",
    "#         t1 = time.time()    \n",
    "        ######################## image sharpening ######################################\n",
    "        sharp_kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])\n",
    "        sh_img = apply_kernel(image.copy(), sharp_kernel)    #sharp image\n",
    "#         print(\"Sharpened image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_sharp\"+\".png\", sh_img)\n",
    "         ######################## end ######################################\n",
    "\n",
    "#         t1 = time.time()\n",
    "        ######################## increase contrast ######################################\n",
    "        inc_cont = increase_contrast(image.copy())\n",
    "#         print(\"Increase contrast {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_cont\"+\".png\", inc_cont)\n",
    "#         ######################## end ######################################\n",
    "\n",
    "\n",
    "#         t1 = time.time()\n",
    "        ######################## Adding noise in images ######################################\n",
    "        noise_img = adding_noise(image.copy())\n",
    "#         print(\"Adding noise in image {} in {} seconds: \".format(image_path, time.time()-t1))\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_noise\"+\".png\", noise_img)\n",
    "#         ######################## end ######################################\n",
    "\n",
    "        img_cnt+=1\n",
    "\n",
    "    ann_csv.reset_index(inplace=True)\n",
    "    ann_csv.drop(columns='level_1', inplace=True)\n",
    "    ann_csv.rename({'level_0':'image_name'}, axis=1, inplace=True)\n",
    "    ann_csv.to_csv(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\".csv\",\n",
    "                  index=False)\n",
    "    print(\"Processed Folder: {}\".format(sub_fold.split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following script are only for flipped of annotated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flip script according to folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random \n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #images folder path\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/FlipImages\"  #saving path for images\n",
    "bag_image_path = \"C:/Users/umar.amanat/Desktop/shopping_bag_images\" #specify folder containing bag images\n",
    "bag_images = list(glob.iglob(os.path.join(bag_image_path, \"*.png\"))) #make list of all bag images in specified folder\n",
    "\n",
    "x_shift = 10    #shifting along x-axis\n",
    "y_shift = 10    #shifting along y-axis\n",
    "\n",
    "#this for loop will iterate over base folder\n",
    "for sub_fold in glob.iglob(img_fold_path+\"/*\"):\n",
    "    img_ann_path = glob.iglob(sub_fold+\"/*.csv\")  #path for annotated csv file\n",
    "    ann_csv = pd.read_csv(list(img_ann_path)[-1])\n",
    "    labels = ann_csv[\"#filename\"] \n",
    "    tuples = list(zip(labels, ann_csv.index.values))\n",
    "    hier_index = pd.MultiIndex.from_tuples(tuples)\n",
    "    ann_csv.set_index(hier_index, inplace=True)\n",
    "    ann_csv.drop(columns=[\"#filename\",\"file_size\", \"region_count\", \"region_id\", \"file_attributes\"], inplace=True)\n",
    "    img_cnt=0\n",
    "    os.makedirs(os.path.join(saving_path, sub_fold.split('\\\\')[-1]))\n",
    "    img_cnt = 0\n",
    "    for image_path, image_name in zip(glob.iglob(os.path.join(sub_fold, \"*.png\")), ann_csv.index.levels[0]):\n",
    "        image = cv2.imread(image_path) #reading image\n",
    "\n",
    "         ####################### Flipping image ######################################\n",
    "        hor_flip = cv2.flip( image.copy(), 1 )\n",
    "         \n",
    "        \n",
    "        for box in ann_csv.loc[image_name].index:\n",
    "            dim = ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"]\n",
    "            json_string = json.loads(dim)\n",
    "            json_string['x'] = image.shape[1] - json_string['x'] - json_string['width']\n",
    "            ann_csv.replace(to_replace=dim, value=str(json_string), inplace=True)\n",
    "            ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"] = str(json_string)\n",
    "        \n",
    "            \"\"\"\n",
    "            following line is for varifying bounding boxes, this will draw bounding boxes after flipping images\n",
    "            un comment immediate subsequent line to draw bounding box\n",
    "            \"\"\"\n",
    "            cv2.rectangle(hor_flip, (json_string['x'], json_string['y']), \n",
    "                          (json_string['x'] + json_string['width'], json_string['y']+json_string['height']), (0, 0, 255), 2)\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_flip\"+\".png\", hor_flip)\n",
    "        #######################end #####################\n",
    "        img_cnt+=1\n",
    "    \n",
    "    ann_csv.reset_index(inplace=True)\n",
    "    ann_csv.drop(columns='level_1', inplace=True)\n",
    "    ann_csv.rename({'level_0':'image_name'}, axis=1, inplace=True)\n",
    "    ann_csv.to_csv(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\".csv\",\n",
    "                  index=False)\n",
    "    print(\"Processed Folder: {}\".format(sub_fold.split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting code according to folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random \n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #images folder path\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/ShiftedImages\"  #saving path for images\n",
    "bag_image_path = \"C:/Users/umar.amanat/Desktop/shopping_bag_images\" #specify folder containing bag images\n",
    "bag_images = list(glob.iglob(os.path.join(bag_image_path, \"*.png\"))) #make list of all bag images in specified folder\n",
    "\n",
    "x_shift = 10    #shifting along x-axis\n",
    "y_shift = 10    #shifting along y-axis\n",
    "\n",
    "#this for loop will iterate over base folder\n",
    "for sub_fold in glob.iglob(img_fold_path+\"/*\"):\n",
    "    #=================================================================================================\n",
    "    img_ann_path = glob.iglob(sub_fold+\"/*.csv\")  #path for annotated csv file\n",
    "    ann_csv = pd.read_csv(list(img_ann_path)[-1])\n",
    "    labels = ann_csv[\"#filename\"] \n",
    "    tuples = list(zip(labels, ann_csv.index.values))\n",
    "    hier_index = pd.MultiIndex.from_tuples(tuples)\n",
    "    ann_csv.set_index(hier_index, inplace=True)\n",
    "    ann_csv.drop(columns=[\"#filename\",\"file_size\", \"region_count\", \"region_id\", \"file_attributes\"], inplace=True)\n",
    "    img_cnt=0\n",
    "    os.makedirs(os.path.join(saving_path, sub_fold.split('\\\\')[-1]))\n",
    "    img_cnt = 0\n",
    "    #===================================================================================================\n",
    "    for image_path, image_name in zip(glob.iglob(os.path.join(sub_fold, \"*.png\")), ann_csv.index.levels[0]):\n",
    "        image = cv2.imread(image_path) #reading image\n",
    "         ####################### Flipping image ######################################\n",
    "        num_rows, num_cols = image.copy().shape[:2]\n",
    "        translation_matrix = np.float32([ [1,0,x_shift], [0,1,y_shift] ])\n",
    "        shf_img = cv2.warpAffine(image.copy(), translation_matrix, (num_cols, num_rows))\n",
    "       \n",
    "        \n",
    "        for box in ann_csv.loc[image_name].index:\n",
    "            dim = ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"]\n",
    "            json_string = json.loads(dim)\n",
    "            json_string['x'] = json_string['x'] + x_shift \n",
    "            json_string['y'] = json_string['y'] + y_shift\n",
    "            ann_csv.replace(to_replace=dim, value=str(json_string), inplace=True)\n",
    "            ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"] = str(json_string)\n",
    "#         #######################end #####################\n",
    "            \"\"\"\n",
    "                following line is for varifying bounding boxes, this will draw bounding boxes after flipping images\n",
    "                un-comment immediate subsequent line to draw bounding box\n",
    "            \"\"\"\n",
    "#             cv2.rectangle(shf_img, (json_string['x'], json_string['y']), \n",
    "#                           (json_string['x'] + json_string['width'], json_string['y']+json_string['height']), (0, 0, 255), 2)\n",
    "        \n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\"_shift\"+\".png\", shf_img)\n",
    "        \n",
    "        \n",
    "        #inner for end here\n",
    "        img_cnt+=1\n",
    "    \n",
    "    ann_csv.reset_index(inplace=True)\n",
    "    ann_csv.drop(columns='level_1', inplace=True)\n",
    "    ann_csv.rename({'level_0':'image_name'}, axis=1, inplace=True)\n",
    "    ann_csv.to_csv(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\".csv\",\n",
    "                  index=False)\n",
    "    print(\"Processed Folder: {}\".format(sub_fold.split('\\\\')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts for overlay transparent image on other background image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def transparentOverlay(src , overlay , pos=(0,0),scale = 1):\n",
    "    \"\"\"\n",
    "    :param src: Input Color Background Image\n",
    "    :param overlay: transparent Image (BGRA)\n",
    "    :param pos:  position where the image to be blit.\n",
    "    :param scale : scale factor of transparent image.\n",
    "    :return: Resultant Image\n",
    "    \"\"\"\n",
    "    overlay = cv2.resize(overlay,(0,0),fx=scale,fy=scale)\n",
    "    h,w,_ = overlay.shape  # Size of foreground\n",
    "    rows,cols,_ = src.shape  # Size of background Image\n",
    "    y,x = pos[0],pos[1]    # Position of foreground/overlay image\n",
    "    #for randomizing placement of ocerlay image\n",
    "    y = random.randint(y, y+20)\n",
    "    x = random.randint(x-5, x+20)\n",
    "    #loop over all pixels and apply the blending equation\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if x+i >= rows or y+j >= cols:\n",
    "                continue\n",
    "            alpha = float(overlay[i][j][3]/255.0) # read the alpha channel \n",
    "            src[x+i][y+j] = alpha*overlay[i][j][:3]+(1-alpha)*src[x+i][y+j]\n",
    "    return src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random \n",
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import regex as re\n",
    "\n",
    "\n",
    "\n",
    "img_fold_path = \"C:/Users/umar.amanat/Desktop/Images\" #images folder path\n",
    "saving_path = \"C:/Users/umar.amanat/Desktop/OverlayImages\"  #saving path for images\n",
    "bag_image_path = \"C:/Users/umar.amanat/Desktop/shopping_bag_images\" #specify folder containing bag images to overlay\n",
    "bag_images = list(glob.iglob(os.path.join(bag_image_path, \"*.png\"))) #make list of all bag images in specified folder\n",
    "\n",
    "\n",
    "#this for loop will iterate over base folder\n",
    "for sub_fold in glob.iglob(img_fold_path+\"/*\"):\n",
    "    img_ann_path = glob.iglob(sub_fold+\"/*.csv\")  #path for annotated csv file\n",
    "    ann_csv = pd.read_csv(list(img_ann_path)[-1])\n",
    "    labels = ann_csv[\"#filename\"] \n",
    "    tuples = list(zip(labels, ann_csv.index.values))\n",
    "    hier_index = pd.MultiIndex.from_tuples(tuples)\n",
    "    ann_csv.set_index(hier_index, inplace=True)\n",
    "    ann_csv.drop(columns=[\"#filename\",\"file_size\", \"region_count\", \"region_id\", \"file_attributes\"], inplace=True)\n",
    "    img_cnt=0\n",
    "    os.makedirs(os.path.join(saving_path, sub_fold.split('\\\\')[-1]))\n",
    "    for image_path, image_name in zip(glob.iglob(os.path.join(sub_fold, \"*.png\")), ann_csv.index.levels[0]):\n",
    "        per_img = cv2.imread(image_path)\n",
    "        for box in ann_csv.loc[image_name].index:\n",
    "            if(random.getrandbits(1) == 1):\n",
    "                #select random bag, cv2.IMR... for reading image as transparent\n",
    "                bag_img = cv2.imread(bag_images[random.randint(1, len(bag_images)-1)], cv2.IMREAD_UNCHANGED)\n",
    "                dim = ann_csv.loc[image_name].loc[box][\"region_shape_attributes\"]\n",
    "                json_string = json.loads(dim)\n",
    "                #generate random size of bag \n",
    "                bag_img = cv2.resize(bag_img, (int(json_string['width']*random.randint(55, 60)/100), \n",
    "                                               int(json_string['height']*random.randint(40, 45)/100))\n",
    "                                    , cv2.INTER_CUBIC)\n",
    "                bag_y = json_string['y'] + json_string['height'] - int(bag_img.shape[0]*1.5)\n",
    "                per_img = transparentOverlay(per_img, bag_img, pos=(json_string['x'], bag_y))\n",
    "                cl = ann_csv.loc[image_name].loc[box][\"region_attributes\"]\n",
    "#                 ann_csv.loc[image_name].loc[box][\"region_attributes\"] = \"PW\"\n",
    "                ann_csv.loc[(image_name, box), \"region_attributes\"] = '{\"Class\":\"PW\"}'\n",
    "\n",
    "        cv2.imwrite(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\n",
    "                    \"_\"+str(img_cnt)+\".png\", per_img)\n",
    "        img_cnt+=1\n",
    "        \n",
    "    ann_csv.reset_index(inplace=True)\n",
    "    ann_csv.drop(columns='level_1', inplace=True)\n",
    "    ann_csv.rename({'level_0':'image_name'}, axis=1, inplace=True)\n",
    "    ann_csv.to_csv(os.path.join(saving_path, sub_fold.split('\\\\')[-1])+\"\\\\\"+sub_fold.split('\\\\')[-1]+\".csv\",\n",
    "                  index=False)\n",
    "    print(\"Processed Folder: {}\".format(sub_fold.split('\\\\')[-1]))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
